{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01_baseline_rng.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"APUKQLQqDnd0"},"source":["# 01_baseline_rng\n","\n","We will use the train/test data generated from *00_create_dataset.ipynb* and use basic machine learning models to generate a baseline reference of model performance on our data. We will then decide on how to improve the various models after this"]},{"cell_type":"code","metadata":{"id":"096C_Ukr5yAS"},"source":["''' data and math '''\n","import pandas as pd\n","import numpy as np\n","\n","''' plotting images '''\n","from matplotlib import pyplot as plt\n","%matplotlib inline\n","\n","''' traversing directories '''\n","import os\n","from pathlib import Path\n","\n","''' utilities '''\n","from tqdm import tqdm\n","\n","''' metrics '''\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import roc_curve"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-tmHXYY6wR1z","executionInfo":{"status":"ok","timestamp":1615485016263,"user_tz":-480,"elapsed":20660,"user":{"displayName":"Chen Ning Teo","photoUrl":"","userId":"00419621925765521583"}},"outputId":"0b48be89-02fd-4f40-add2-cdd2c0195445"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zYLxrJY66wVn","executionInfo":{"status":"ok","timestamp":1615485017234,"user_tz":-480,"elapsed":21620,"user":{"displayName":"Chen Ning Teo","photoUrl":"","userId":"00419621925765521583"}},"outputId":"d21c9ca4-ac7c-4aa2-cda4-65a3eb5b80b5"},"source":["''' used to reference the root directory, for directory traversal ''' \n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","mount_dir = '/content/gdrive'\n","root_dir = Path('/content/gdrive/My Drive/it3011_project')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4ABDyA96vaoD"},"source":["# Loading data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0sgaXjzb5-Vs","executionInfo":{"status":"ok","timestamp":1615485039157,"user_tz":-480,"elapsed":43535,"user":{"displayName":"Chen Ning Teo","photoUrl":"","userId":"00419621925765521583"}},"outputId":"20ab24b2-93be-475f-8ce6-8c267abb3830"},"source":["# load data\n","train = pd.read_csv(root_dir/\"data/train.csv\")\n","test = pd.read_csv(root_dir/\"data/test.csv\")\n","print(\"data loaded\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["data loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"do5mAxc-0noF","executionInfo":{"status":"ok","timestamp":1615485039158,"user_tz":-480,"elapsed":43529,"user":{"displayName":"Chen Ning Teo","photoUrl":"","userId":"00419621925765521583"}},"outputId":"0e8154cd-6224-4710-ca90-9d562aac51ad"},"source":["# check shape\n","print(train.shape)\n","print(test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(280145, 138)\n","(120504, 138)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJ1gWmKfaE59","executionInfo":{"status":"ok","timestamp":1615485040189,"user_tz":-480,"elapsed":44555,"user":{"displayName":"Chen Ning Teo","photoUrl":"","userId":"00419621925765521583"}},"outputId":"30c4864f-fd4c-4de8-ad04-f4af2e4fb4b6"},"source":["# create train/test sets\n","features = [feature for feature in test.keys() if \"feature\" in feature]\n","x_train = train.loc[:, features].values\n","y_train = train.loc[:,['action']].values.flatten()\n","x_test = test.loc[:, features].values\n","y_test = test.loc[:,['action']].values.flatten()\n","print(\"train/test set created\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train/test set created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bCcZ6_5RP3CI"},"source":["# scaling data to make it easier for models to train\n","from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler().fit(x_train)\n","x_train = scaler.transform(x_train)\n","\n","# test set scaled on the same scaler as train, because models are fitted on the train distributions and not test distributions\n","x_test = scaler.transform(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KFuaPWdo39ff"},"source":["# Helper functions"]},{"cell_type":"code","metadata":{"id":"Ca00riNuRmIa"},"source":["# constants\n","SEED = 42"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P09ivaKS38-l"},"source":["# create the utility score, which takes in the prediction value and the ground truth action and generates a score\n","# link: https://www.kaggle.com/c/jane-street-market-prediction/overview/evaluation\n","\n","# data: original train/test data    action: the y-value. can either be y_pred or original values too, if we want the max score attainable\n","def utility_score(data, action): \n","  dates_set = set(data.date.values)\n","  dates = data.loc[:, ['date']].values.flatten()\n","  weights = data.loc[:, ['weight']].values.flatten()\n","  resps = data.loc[:, ['resp']].values.flatten()\n","  actions = action.flatten()\n","\n","  i = len(dates_set)\n","  p_i = []\n","\n","  for date in dates_set:\n","    indices = np.where(dates == date)[0]\n","    p_i_temp = 0\n","    for j in indices:\n","      p_i_temp = p_i_temp + weights[j] * resps[j] * actions[j]\n","    p_i.append(p_i_temp)\n","  \n","  p_i_squared = [p_i1*p_i2 for p_i1,p_i2 in zip(p_i,p_i)]\n","  t = ( sum(p_i) / np.sqrt(sum(p_i_squared)) ) * np.sqrt(250/i)\n","  u = min(max(t, 0), 6) * sum(p_i)\n","\n","  return u\n","\n","def max_train_utility_score(data=train, action=y_train):\n","  return utility_score(data, action)\n","\n","def max_test_utility_score(data=test, action=y_test):\n","  return utility_score(data, action)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vg7v_N3iUfwF"},"source":["def model_scores(model, test=test, x_test=x_test, y_test=y_test):\n","  y_pred = model.predict(x_test) \n","\n","  print(\"Utility score: \", utility_score(test, y_pred))\n","  print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n","  \n","  print(\"Confusion matrix\")\n","  cm = confusion_matrix(y_test, y_pred)\n","  fig, ax = plt.subplots(figsize=(3, 3))\n","  ax.imshow(cm)\n","  ax.grid(False)\n","  ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n","  ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n","  ax.set_ylim(1.5, -0.5)\n","  for i in range(2):\n","      for j in range(2):\n","          ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n","  plt.show()  \n","\n","  print(\"AUC_ROC\")\n","  logit_roc_auc = roc_auc_score(y_test, model.predict(x_test))\n","  fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(x_test)[:,1])\n","  plt.figure()\n","  plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n","  plt.plot([0, 1], [0, 1],'r--')\n","  plt.xlim([0.0, 1.0])\n","  plt.ylim([0.0, 1.05])\n","  plt.xlabel('False Positive Rate')\n","  plt.ylabel('True Positive Rate')\n","  plt.title('Receiver operating characteristic')\n","  plt.legend(loc=\"lower right\")\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zrwUKgT48lD8"},"source":["# RNG model\n","We just want to have a baseline to ensure our models are not worse than randomly generated predictions"]},{"cell_type":"code","metadata":{"id":"vKwcEJp0okYo"},"source":["utility_scores = []\n","accuracies = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HAYe4qKGSImo","executionInfo":{"status":"ok","timestamp":1615485057335,"user_tz":-480,"elapsed":61665,"user":{"displayName":"Chen Ning Teo","photoUrl":"","userId":"00419621925765521583"}},"outputId":"f8eadea7-833f-49ec-9867-ca9e6a981f91"},"source":["for i in range(100):\n","  y_pred = np.random.randint(2, size=y_test.shape[0])\n","\n","  utility_scores.append(utility_score(test, y_pred))\n","  accuracies.append(accuracy_score(y_test, y_pred))\n","\n","print(\"Average over 100 random sets of predictions\")\n","print(\"Average utility score: \", np.mean(utility_scores))\n","print(\"Average accuracy: \", np.mean(accuracies))\n","  \n","print(max_test_utility_score())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Average over 100 random sets of predictions\n","Average utility score:  2.7722394525332903\n","Average accuracy:  0.5001530239660095\n","15405.02761054398\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5Ha1Hl44pbCz"},"source":["# Conclusion"]},{"cell_type":"markdown","metadata":{"id":"m97QASIApcuw"},"source":["Our models should at least do better than our randomly generated samples \n","* Average utility score:  3.806295340430403\n","* Average accuracy:  0.5000910758149107"]},{"cell_type":"code","metadata":{"id":"RVfUgAUxqR33"},"source":[""],"execution_count":null,"outputs":[]}]}