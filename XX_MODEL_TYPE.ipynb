{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"XX_MODEL_TYPE.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP9TydilAhdPCnLVjqmu2rq"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"APUKQLQqDnd0"},"source":["# XX_MODEL_TYPE.ipynb\r\n","\r\n","We will use the train/test data generated from *00_create_dataset.ipynb* and perform **describe**"]},{"cell_type":"code","metadata":{"id":"096C_Ukr5yAS"},"source":["''' data and math '''\r\n","import pandas as pd\r\n","import numpy as np\r\n","\r\n","''' plotting images '''\r\n","from matplotlib import pyplot as plt\r\n","%matplotlib inline\r\n","\r\n","''' traversing directories '''\r\n","import os\r\n","from pathlib import Path\r\n","\r\n","''' utilities '''\r\n","from tqdm import tqdm\r\n","\r\n","''' metrics '''\r\n","from sklearn.metrics import accuracy_score\r\n","from sklearn.metrics import confusion_matrix\r\n","from sklearn.metrics import roc_auc_score\r\n","from sklearn.metrics import roc_curve"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-tmHXYY6wR1z","executionInfo":{"status":"ok","timestamp":1615453249626,"user_tz":-480,"elapsed":15030,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}},"outputId":"4ea7a9b3-fe6e-4bac-df4c-a5e095c3d953"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zYLxrJY66wVn","executionInfo":{"status":"ok","timestamp":1615453250788,"user_tz":-480,"elapsed":16183,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}},"outputId":"255f1dbc-91c0-41de-980f-87cdbe38cce4"},"source":["''' used to reference the root directory, for directory traversal ''' \r\n","from google.colab import drive\r\n","drive.mount('/content/gdrive', force_remount=True)\r\n","mount_dir = '/content/gdrive'\r\n","root_dir = Path('/content/gdrive/My Drive/it3011_project')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4ABDyA96vaoD"},"source":["# Loading data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0sgaXjzb5-Vs","executionInfo":{"status":"ok","timestamp":1615453269680,"user_tz":-480,"elapsed":35066,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}},"outputId":"f712c822-0d6e-4cfb-e6b1-6072595a6677"},"source":["# load data\r\n","train = pd.read_csv(root_dir/\"data/train.csv\")\r\n","test = pd.read_csv(root_dir/\"data/test.csv\")\r\n","print(\"data loaded\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["data loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"do5mAxc-0noF","executionInfo":{"status":"ok","timestamp":1615453269683,"user_tz":-480,"elapsed":35060,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}},"outputId":"5bab6bfd-e2e2-489b-f9c5-1fc265bfd67c"},"source":["# check shape\r\n","print(train.shape)\r\n","print(test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(280145, 139)\n","(120504, 139)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJ1gWmKfaE59","executionInfo":{"status":"ok","timestamp":1615453269687,"user_tz":-480,"elapsed":35055,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}},"outputId":"28919524-7a3d-4ba1-dacb-6554e050eae3"},"source":["# create train/test sets\r\n","features = [feature for feature in test.keys() if \"feature\" in feature]\r\n","x_train = train.loc[:, features].values\r\n","y_train = train.loc[:,['action']].values.flatten()\r\n","x_test = test.loc[:, features].values\r\n","y_test = test.loc[:,['action']].values.flatten()\r\n","print(\"train/test set created\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train/test set created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bCcZ6_5RP3CI"},"source":["# scaling data to make it easier for models to train\r\n","from sklearn.preprocessing import StandardScaler\r\n","\r\n","scaler = StandardScaler().fit(x_train)\r\n","x_train = scaler.transform(x_train)\r\n","\r\n","# test set scaled on the same scaler as train, because models are fitted on the train distributions and not test distributions\r\n","x_test = scaler.transform(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KFuaPWdo39ff"},"source":["# Helper functions"]},{"cell_type":"code","metadata":{"id":"Ca00riNuRmIa"},"source":["# constants\r\n","SEED = 42"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P09ivaKS38-l"},"source":["# create the utility score, which takes in the prediction value and the ground truth action and generates a score\r\n","# link: https://www.kaggle.com/c/jane-street-market-prediction/overview/evaluation\r\n","\r\n","# data: original train/test data    action: the y-value. can either be y_pred or original values too, if we want the max score attainable\r\n","def utility_score(data, action): \r\n","  dates_set = set(data.date.values)\r\n","  dates = data.loc[:, ['date']].values.flatten()\r\n","  weights = data.loc[:, ['weight']].values.flatten()\r\n","  resps = data.loc[:, ['resp']].values.flatten()\r\n","  actions = action.flatten()\r\n","\r\n","  i = len(dates_set)\r\n","  p_i = []\r\n","\r\n","  for date in dates_set:\r\n","    indices = np.where(dates == date)[0]\r\n","    p_i_temp = 0\r\n","    for j in indices:\r\n","      p_i_temp = p_i_temp + weights[j] * resps[j] * actions[j]\r\n","    p_i.append(p_i_temp)\r\n","  \r\n","  p_i_squared = [p_i1*p_i2 for p_i1,p_i2 in zip(p_i,p_i)]\r\n","  t = ( sum(p_i) / np.sqrt(sum(p_i_squared)) ) * np.sqrt(250/i)\r\n","  u = min(max(t, 0), 6) * sum(p_i)\r\n","\r\n","  return u\r\n","\r\n","def max_train_utility_score(data=train, action=y_train):\r\n","  return utility_score(data, action)\r\n","\r\n","def max_test_utility_score(data=test, action=y_test):\r\n","  return utility_score(data, action)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vg7v_N3iUfwF"},"source":["def model_scores(model, test=test, x_test=x_test, y_test=y_test):\r\n","  y_pred = model.predict(x_test) \r\n","\r\n","  print(\"Utility score: \", utility_score(test, y_pred))\r\n","  print(\"Accuracy: \", accuracy_score(y_test, y_pred))\r\n","  \r\n","  print(\"Confusion matrix\")\r\n","  cm = confusion_matrix(y_test, y_pred)\r\n","  fig, ax = plt.subplots(figsize=(3, 3))\r\n","  ax.imshow(cm)\r\n","  ax.grid(False)\r\n","  ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\r\n","  ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\r\n","  ax.set_ylim(1.5, -0.5)\r\n","  for i in range(2):\r\n","      for j in range(2):\r\n","          ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\r\n","  plt.show()  \r\n","\r\n","  print(\"AUC_ROC\")\r\n","  logit_roc_auc = roc_auc_score(y_test, model.predict(x_test))\r\n","  fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(x_test)[:,1])\r\n","  plt.figure()\r\n","  plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\r\n","  plt.plot([0, 1], [0, 1],'r--')\r\n","  plt.xlim([0.0, 1.0])\r\n","  plt.ylim([0.0, 1.05])\r\n","  plt.xlabel('False Positive Rate')\r\n","  plt.ylabel('True Positive Rate')\r\n","  plt.title('Receiver operating characteristic')\r\n","  plt.legend(loc=\"lower right\")\r\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rXTMuwYsa7mG"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"R0ej1__vab0U"},"source":[""],"execution_count":null,"outputs":[]}]}